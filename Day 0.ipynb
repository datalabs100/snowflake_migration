{
 "metadata": {
  "kernelspec": {
   "display_name": "Streamlit Notebook",
   "name": "streamlit"
  },
  "lastEditStatus": {
   "notebookId": "p4xlrka6zrviclvkxrnu",
   "authorId": "7599755599173",
   "authorName": "ZUBAIR2216",
   "authorEmail": "datalabs200@gmail.com",
   "sessionId": "2c6b8599-7f5d-4f24-860e-0ece3cfaeb58",
   "lastEditTime": 1751973648566
  }
 },
 "nbformat_minor": 5,
 "nbformat": 4,
 "cells": [
  {
   "cell_type": "code",
   "id": "3775908f-ca36-4846-8f38-5adca39217f2",
   "metadata": {
    "language": "sql",
    "name": "cell1"
   },
   "source": "USE DATABASE DEV;\nUSE SCHEMA DATASCIENCE;",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "id": "8d50cbf4-0c8d-4950-86cb-114990437ac9",
   "metadata": {
    "language": "sql",
    "name": "cell2"
   },
   "source": "CREATE OR REPLACE FILE FORMAT my_parquet_format\n  TYPE = 'PARQUET';",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "id": "c695373e-ac74-4b62-a1f1-08206cbd5c81",
   "metadata": {
    "language": "sql",
    "name": "cell3"
   },
   "source": "CREATE OR REPLACE STAGE bronze_xml\n  URL = 's3://datascience-output-bucket/bronze/xml/'\n  STORAGE_INTEGRATION = aws_snowflake_connect\n  FILE_FORMAT = my_parquet_format;",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "id": "d1e2f076-e5fc-4863-a563-0f6dd3c1be92",
   "metadata": {
    "language": "sql",
    "name": "cell4"
   },
   "outputs": [],
   "source": "CREATE OR REPLACE TABLE customers (\n  customer_id   INT,\n  customer_name STRING,\n  start_date TIMESTAMP_NTZ\n);\n\nCREATE OR REPLACE TABLE products (\n  product_id    STRING,         \n  product_name  STRING,\n  start_date    TIMESTAMP_NTZ\n);\n\nCREATE OR REPLACE TABLE orders (\n  order_id     STRING,        \n  customer_id  INT,\n  product_id   STRING,\n  start_date   TIMESTAMP_NTZ\n);",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "f0a4deb8-479f-42ed-b9d0-6dad8e7cbd7f",
   "metadata": {
    "language": "python",
    "name": "cell6"
   },
   "outputs": [],
   "source": "from datetime import datetime\nfrom snowflake.snowpark import Session\nimport time\n\n# Step 1: Use UTC to avoid local timezone mismatch\nfolder_path = datetime.utcnow().strftime(\"%Y/%b/%d/\").title()\n\n# Step 2: Snowflake connection config\nconnection_parameters = {\n    \"account\": \"PL49411.ap-southeast-1\",\n    \"user\": \"ZUBAIR2216\",\n    \"password\": \"Datalabs@193001\",\n    \"role\": \"ACCOUNTADMIN\",\n    \"warehouse\": \"COMPUTE_WH\",\n    \"database\": \"DEV\",\n    \"schema\": \"DATASCIENCE\"\n}\n\ntry:\n    # Step 3: Create session\n    session = Session.builder.configs(connection_parameters).create()\n\n    # Step 4: COPY INTO customers\n    copy_customers = f\"\"\"\n    COPY INTO customers\n    FROM @bronze_xml/{folder_path}\n    FILE_FORMAT = (FORMAT_NAME = my_parquet_format)\n    MATCH_BY_COLUMN_NAME = CASE_INSENSITIVE\n    PATTERN = '.*Customers_.*\\\\.parquet';\n    \"\"\"\n    session.sql(copy_customers).collect()\n    print(\"âœ… Customers loaded\")\n\n    # Step 5: COPY INTO products\n    copy_products = f\"\"\"\n    COPY INTO products\n    FROM @bronze_xml/{folder_path}\n    FILE_FORMAT = (FORMAT_NAME = my_parquet_format)\n    MATCH_BY_COLUMN_NAME = CASE_INSENSITIVE\n    PATTERN = '.*Products_.*\\\\.parquet';\n    \"\"\"\n    session.sql(copy_products).collect()\n    print(\"âœ… Products loaded\")\n\n    # Step 6: COPY INTO orders\n    copy_orders = f\"\"\"\n    COPY INTO orders\n    FROM @bronze_xml/{folder_path}\n    FILE_FORMAT = (FORMAT_NAME = my_parquet_format)\n    MATCH_BY_COLUMN_NAME = CASE_INSENSITIVE\n    PATTERN = '.*Orders_.*\\\\.parquet';\n    \"\"\"\n    session.sql(copy_orders).collect()\n    print(\"âœ… Orders loaded\")\n\nfinally:\n    # Step 7: Always close session\n    session.sql(\"COMMIT\").collect()\n    session.close()\n    print(\"ðŸ”’ Session closed\")",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "52267f5b-dd8a-44be-8e9c-02c9694fda90",
   "metadata": {
    "language": "python",
    "name": "cell10"
   },
   "outputs": [],
   "source": "print(folder_path)",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "3304bc3a-c647-41e6-95ae-807f55a96f6e",
   "metadata": {
    "language": "python",
    "name": "cell5"
   },
   "outputs": [],
   "source": "# Show top 10 rows from customers table\ndf = session.table(\"customers\").limit(10)\ndf.show()",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "a420e7e9-685d-42ab-995d-9a92bc428911",
   "metadata": {
    "language": "python",
    "name": "cell7"
   },
   "outputs": [],
   "source": "from snowflake.snowpark import Session\nfrom snowflake.snowpark.functions import (\n    col, lit, row_number, sql_expr\n)\nfrom snowflake.snowpark.window import Window\nfrom datetime import datetime\n\n# Assumes already defined above\n# folder_path = datetime.utcnow().strftime(\"%Y/%b/%d/\").title()\n# connection_parameters = { ... }\n\n# Step 1: Create session\nsession = Session.builder.configs(connection_parameters).create()\n\n# Step 2: Load bronze tables\ncustomers = session.table(\"customers\")\nproducts = session.table(\"products\")\norders = session.table(\"orders\")\n\n# Step 3: Filter NULLs in required fields\ncustomers_clean = customers.filter((col(\"customer_id\").is_not_null()) & (col(\"customer_name\").is_not_null()))\nproducts_clean = products.filter((col(\"product_id\").is_not_null()) & (col(\"product_name\").is_not_null()))\norders_clean = orders.filter(\n    (col(\"order_id\").is_not_null()) &\n    (col(\"customer_id\").is_not_null()) &\n    (col(\"product_id\").is_not_null())\n)\n\n# Step 4: Prepare Load Date and End Date with timestamp precision\nnow = sql_expr(\"TO_TIMESTAMP_NTZ(TO_CHAR(CURRENT_TIMESTAMP(), 'YYYY-MM-DD HH24:MI:SS'))\")\nend_datetime = sql_expr(\"TO_TIMESTAMP_NTZ('2099-12-31 23:59:59')\")\n\n# Step 5: Transform and cast columns\ncustomers_t = customers_clean \\\n    .with_column(\"customer_id\", col(\"customer_id\").cast(\"int\")) \\\n    .with_column(\"customer_name\", col(\"customer_name\").cast(\"string\")) \\\n    .with_column(\"start_date\", col(\"start_date\").cast(\"timestamp\")) \\\n    .with_column(\"load_date\", now)\n\nproducts_t = products_clean \\\n    .with_column(\"product_id\", col(\"product_id\").cast(\"string\")) \\\n    .with_column(\"product_name\", col(\"product_name\").cast(\"string\")) \\\n    .with_column(\"start_date\", col(\"start_date\").cast(\"timestamp\")) \\\n    .with_column(\"load_date\", now)\n\norders_t = orders_clean \\\n    .with_column(\"order_id\", col(\"order_id\").cast(\"string\")) \\\n    .with_column(\"customer_id\", col(\"customer_id\").cast(\"int\")) \\\n    .with_column(\"product_id\", col(\"product_id\").cast(\"string\")) \\\n    .with_column(\"start_date\", col(\"start_date\").cast(\"timestamp\")) \\\n    .with_column(\"load_date\", now) \\\n    .with_column(\"end_date\", end_datetime)\n\n# Step 6: Add surrogate keys and reorder columns\ncustomers_final = customers_t.with_column(\n    \"customer_sk\", row_number().over(Window.order_by(\"customer_id\")) + 1000\n).select(\n    \"customer_id\",\n    \"customer_sk\",\n    \"customer_name\",\n    \"start_date\",\n    \"load_date\"\n)\n\nproducts_final = products_t.with_column(\n    \"product_sk\", row_number().over(Window.order_by(\"product_id\")) + 2000\n).select(\n    \"product_id\",\n    \"product_sk\",\n    \"product_name\",\n    \"start_date\",\n    \"load_date\"\n)\n\norders_final = orders_t.select(\n    \"order_id\",\n    \"customer_id\",\n    \"product_id\",\n    \"start_date\",\n    \"load_date\",\n    \"end_date\"\n)\n\n# Step 7: Save to silver Snowflake tables\ncustomers_final.write.mode(\"overwrite\").save_as_table(\"customers_silver\")\nproducts_final.write.mode(\"overwrite\").save_as_table(\"products_silver\")\norders_final.write.mode(\"overwrite\").save_as_table(\"orders_silver\")\n\nprint(\"âœ… Silver tables created with correct column order and timestamp formatting\")\n\n# Step 8: Create silver stage if not exists\nsession.sql(f\"\"\"\nCREATE OR REPLACE STAGE silver_xml\nURL = 's3://datascience-output-bucket/silver/xml/'\nSTORAGE_INTEGRATION = aws_snowflake_connect\nFILE_FORMAT = (TYPE = PARQUET COMPRESSION = SNAPPY)\n\"\"\").collect()\n\n# Step 9: Export tables to S3 with TIMESTAMP_NTZ formatting\nsession.sql(f\"\"\"\nCOPY INTO @silver_xml/{folder_path}Customers.parquet\nFROM (\n    SELECT\n        customer_id,\n        customer_sk,\n        customer_name,\n        CAST(start_date AS TIMESTAMP_NTZ) AS start_date,\n        CAST(load_date AS TIMESTAMP_NTZ) AS load_date\n    FROM customers_silver\n)\nFILE_FORMAT = (TYPE = PARQUET COMPRESSION = SNAPPY)\nSINGLE = TRUE\nOVERWRITE = TRUE;\n\"\"\").collect()\n\nsession.sql(f\"\"\"\nCOPY INTO @silver_xml/{folder_path}Products.parquet\nFROM (\n    SELECT\n        product_id,\n        product_sk,\n        product_name,\n        CAST(start_date AS TIMESTAMP_NTZ) AS start_date,\n        CAST(load_date AS TIMESTAMP_NTZ) AS load_date\n    FROM products_silver\n)\nFILE_FORMAT = (TYPE = PARQUET COMPRESSION = SNAPPY)\nSINGLE = TRUE\nOVERWRITE = TRUE;\n\"\"\").collect()\n\nsession.sql(f\"\"\"\nCOPY INTO @silver_xml/{folder_path}Orders.parquet\nFROM (\n    SELECT\n        order_id,\n        customer_id,\n        product_id,\n        CAST(start_date AS TIMESTAMP_NTZ) AS start_date,\n        CAST(load_date AS TIMESTAMP_NTZ) AS load_date,\n        CAST(end_date AS TIMESTAMP_NTZ) AS end_date\n    FROM orders_silver\n)\nFILE_FORMAT = (TYPE = PARQUET COMPRESSION = SNAPPY)\nSINGLE = TRUE\nOVERWRITE = TRUE;\n\"\"\").collect()\n\nprint(\"âœ… Parquet files exported with timestamps truncated to seconds\")\nsession.close()\nprint(\"ðŸ”’ Session closed\")",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "97cbe57f-c18b-404c-8692-8ba23ac3917f",
   "metadata": {
    "language": "python",
    "name": "cell8"
   },
   "outputs": [],
   "source": "df = session.table(\"orders_silver\").limit(10)\ndf.show()",
   "execution_count": null
  }
 ]
}